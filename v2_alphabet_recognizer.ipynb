{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CW-v2-alphabet-recognizer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "9236e0d3-e264-4630-f079-7c62dcaf56cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "metadata": {
        "id": "18ybArgjaXzo",
        "colab_type": "code",
        "outputId": "3a075d41-e902-4ecf-bf14-54e62f5196fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_train = \"/content/drive/My Drive/Datasets/emnist-balanced-train.csv\"\n",
        "path_test = \"/content/drive/My Drive/Datasets/emnist-balanced-test.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tlwrzddL-v55",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(path_train,header=None)\n",
        "test  = pd.read_csv(path_test,header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dmd9je7wIWdG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = train.iloc[:, 1:]\n",
        "train_labels = train.iloc[:, 0]\n",
        "test_data = test.iloc[:, 1:]\n",
        "test_labels = test.iloc[:, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXip_fGSIWZp",
        "colab_type": "code",
        "outputId": "e0acee4f-d9a7-4ffb-a143-929ea85c71f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels = pd.get_dummies(train_labels)\n",
        "test_labels = pd.get_dummies(test_labels)\n",
        "train_labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0   1   2   3   4   5   6   7   8   9  ...  37  38  39  40  41  42  43  44  \\\n",
              "0   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
              "1   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
              "2   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   1   0   \n",
              "3   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
              "4   0   0   0   0   1   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
              "\n",
              "   45  46  \n",
              "0   1   0  \n",
              "1   0   0  \n",
              "2   0   0  \n",
              "3   0   0  \n",
              "4   0   0  \n",
              "\n",
              "[5 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "AoZLlKcoIWWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = train_data.values\n",
        "train_labels = train_labels.values\n",
        "test_data = test_data.values\n",
        "test_labels = test_labels.values\n",
        "del train, test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eB3oAXm3IWUt",
        "colab_type": "code",
        "outputId": "b14e4270-970e-444e-df52-33697c1ab617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(train_data[45].reshape([28, 28]), cmap='Greys_r')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f94e8081358>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8ezb_y0QIWQv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rotate(image):\n",
        "    image = image.reshape([28, 28])\n",
        "    image = np.fliplr(image)\n",
        "    image = np.rot90(image)\n",
        "    return image.reshape([28 * 28])\n",
        "train_data = np.apply_along_axis(rotate, 1, train_data)/255\n",
        "test_data = np.apply_along_axis(rotate, 1, test_data)/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o7ewLPP0IWNJ",
        "colab_type": "code",
        "outputId": "8184cf38-3ec8-43a1-99ea-be895a6f1c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(train_data[45].reshape([28, 28]), cmap='Greys_r')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w9FakHkjeENwAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f94874524a8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1vwyLN_PIWJv",
        "colab_type": "code",
        "outputId": "d0540886-17ce-4ca6-b2f7-4409111cd445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(train_data[345].reshape([28, 28]), cmap='Greys_r')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f94878eb9e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "zR3kMIEhExDs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = train_data \n",
        "Y_train = train_labels \n",
        "X_test = test_data \n",
        "Y_test = test_labels "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "e2ece435-68c8-449e-87b5-46e45c726235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation , MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32,3,3,activation='relu',input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(16,3,3,activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Convolution2D(24,3,3,activation='relu'))\n",
        "model.add(Convolution2D(16,3,3,activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.27))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.27))\n",
        "model.add(Dense(47, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 24)        3480      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 16)          3472      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 47)                12079     \n",
            "=================================================================\n",
            "Total params: 23,975\n",
            "Trainable params: 23,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='SGD',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k49C_BzLXEOw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gen = datagen = ImageDataGenerator(\n",
        "        featurewise_center=False, \n",
        "        samplewise_center=False,  \n",
        "        featurewise_std_normalization=False, \n",
        "        samplewise_std_normalization=False, \n",
        "        zca_whitening=False,  \n",
        "        rotation_range=10,  \n",
        "        zoom_range = 0.1,  \n",
        "        width_shift_range=0.1,  \n",
        "        height_shift_range=0.1, \n",
        "        horizontal_flip=False,  \n",
        "        vertical_flip=False)  \n",
        "\n",
        "train_generator = gen.flow(X_train, Y_train, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E5mQT4mDXLuA",
        "colab_type": "code",
        "outputId": "070f22d1-a8e4-44a7-d936-7bf48255e879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch=697931//64, epochs=15, \n",
        "                    validation_data=(X_test,Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "10905/10905 [==============================] - 306s 28ms/step - loss: 0.6792 - acc: 0.7813 - val_loss: 0.3879 - val_acc: 0.8667\n",
            "Epoch 2/15\n",
            "10905/10905 [==============================] - 308s 28ms/step - loss: 0.6343 - acc: 0.7952 - val_loss: 0.3728 - val_acc: 0.8724\n",
            "Epoch 3/15\n",
            "10905/10905 [==============================] - 310s 28ms/step - loss: 0.6166 - acc: 0.7998 - val_loss: 0.3873 - val_acc: 0.8703\n",
            "Epoch 4/15\n",
            "10905/10905 [==============================] - 299s 27ms/step - loss: 0.6010 - acc: 0.8045 - val_loss: 0.3798 - val_acc: 0.8693\n",
            "Epoch 5/15\n",
            "10905/10905 [==============================] - 303s 28ms/step - loss: 0.5907 - acc: 0.8070 - val_loss: 0.3924 - val_acc: 0.8695\n",
            "Epoch 6/15\n",
            "10905/10905 [==============================] - 303s 28ms/step - loss: 0.5810 - acc: 0.8092 - val_loss: 0.3904 - val_acc: 0.8680\n",
            "Epoch 7/15\n",
            "10905/10905 [==============================] - 301s 28ms/step - loss: 0.5770 - acc: 0.8109 - val_loss: 0.3987 - val_acc: 0.8663\n",
            "Epoch 8/15\n",
            "10905/10905 [==============================] - 296s 27ms/step - loss: 0.5684 - acc: 0.8134 - val_loss: 0.3687 - val_acc: 0.8746\n",
            "Epoch 9/15\n",
            "10905/10905 [==============================] - 301s 28ms/step - loss: 0.5640 - acc: 0.8148 - val_loss: 0.3767 - val_acc: 0.8729\n",
            "Epoch 10/15\n",
            "10905/10905 [==============================] - 298s 27ms/step - loss: 0.5575 - acc: 0.8166 - val_loss: 0.3873 - val_acc: 0.8730\n",
            "Epoch 11/15\n",
            "10905/10905 [==============================] - 301s 28ms/step - loss: 0.5542 - acc: 0.8172 - val_loss: 0.3956 - val_acc: 0.8677\n",
            "Epoch 12/15\n",
            "10905/10905 [==============================] - 297s 27ms/step - loss: 0.5492 - acc: 0.8190 - val_loss: 0.3693 - val_acc: 0.8747\n",
            "Epoch 13/15\n",
            "10905/10905 [==============================] - 307s 28ms/step - loss: 0.5457 - acc: 0.8194 - val_loss: 0.3732 - val_acc: 0.8744\n",
            "Epoch 14/15\n",
            "10905/10905 [==============================] - 305s 28ms/step - loss: 0.5426 - acc: 0.8209 - val_loss: 0.3870 - val_acc: 0.8698\n",
            "Epoch 15/15\n",
            "10905/10905 [==============================] - 306s 28ms/step - loss: 0.5411 - acc: 0.8213 - val_loss: 0.3690 - val_acc: 0.8751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff90ae5cb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "-7Cq1iLXMaJl",
        "colab_type": "code",
        "outputId": "b2d13ffb-4acb-417b-bc45-635294160403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train,batch_size=32,epochs=15,verbose=1,validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 112800 samples, validate on 18800 samples\n",
            "Epoch 1/15\n",
            "112800/112800 [==============================] - 38s 338us/step - loss: 2.3865 - acc: 0.3558 - val_loss: 0.9215 - val_acc: 0.7301\n",
            "Epoch 2/15\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 1.0509 - acc: 0.6786 - val_loss: 0.6646 - val_acc: 0.7903\n",
            "Epoch 3/15\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.8528 - acc: 0.7334 - val_loss: 0.5922 - val_acc: 0.8079\n",
            "Epoch 4/15\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.7710 - acc: 0.7550 - val_loss: 0.5438 - val_acc: 0.8232\n",
            "Epoch 5/15\n",
            "112800/112800 [==============================] - 34s 305us/step - loss: 0.7200 - acc: 0.7690 - val_loss: 0.5161 - val_acc: 0.8332\n",
            "Epoch 6/15\n",
            "112800/112800 [==============================] - 34s 302us/step - loss: 0.6780 - acc: 0.7812 - val_loss: 0.5041 - val_acc: 0.8360\n",
            "Epoch 7/15\n",
            "112800/112800 [==============================] - 34s 305us/step - loss: 0.6538 - acc: 0.7879 - val_loss: 0.4801 - val_acc: 0.8419\n",
            "Epoch 8/15\n",
            "112800/112800 [==============================] - 34s 305us/step - loss: 0.6353 - acc: 0.7944 - val_loss: 0.4702 - val_acc: 0.8432\n",
            "Epoch 9/15\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.6182 - acc: 0.7989 - val_loss: 0.4599 - val_acc: 0.8469\n",
            "Epoch 10/15\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.6031 - acc: 0.8038 - val_loss: 0.4520 - val_acc: 0.8497\n",
            "Epoch 11/15\n",
            "112800/112800 [==============================] - 34s 302us/step - loss: 0.5913 - acc: 0.8059 - val_loss: 0.4491 - val_acc: 0.8518\n",
            "Epoch 12/15\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.5816 - acc: 0.8095 - val_loss: 0.4412 - val_acc: 0.8529\n",
            "Epoch 13/15\n",
            "112800/112800 [==============================] - 34s 302us/step - loss: 0.5705 - acc: 0.8119 - val_loss: 0.4377 - val_acc: 0.8519\n",
            "Epoch 14/15\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.5569 - acc: 0.8156 - val_loss: 0.4286 - val_acc: 0.8573\n",
            "Epoch 15/15\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.5576 - acc: 0.8164 - val_loss: 0.4287 - val_acc: 0.8580\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff92ad993c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "LPwy9KIsSTiy",
        "colab_type": "code",
        "outputId": "6c7b21ab-c0d3-4807-e112-d348e2b331be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train,batch_size=32,epochs=50,verbose=1,validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 112800 samples, validate on 18800 samples\n",
            "Epoch 1/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.5448 - acc: 0.8187 - val_loss: 0.4192 - val_acc: 0.8602\n",
            "Epoch 2/50\n",
            "112800/112800 [==============================] - 35s 307us/step - loss: 0.5404 - acc: 0.8218 - val_loss: 0.4200 - val_acc: 0.8578\n",
            "Epoch 3/50\n",
            "112800/112800 [==============================] - 34s 305us/step - loss: 0.5343 - acc: 0.8212 - val_loss: 0.4168 - val_acc: 0.8609\n",
            "Epoch 4/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.5285 - acc: 0.8240 - val_loss: 0.4115 - val_acc: 0.8616\n",
            "Epoch 5/50\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.5249 - acc: 0.8246 - val_loss: 0.4163 - val_acc: 0.8556\n",
            "Epoch 6/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.5197 - acc: 0.8260 - val_loss: 0.4055 - val_acc: 0.8621\n",
            "Epoch 7/50\n",
            "112800/112800 [==============================] - 34s 305us/step - loss: 0.5138 - acc: 0.8281 - val_loss: 0.4178 - val_acc: 0.8581\n",
            "Epoch 8/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.5103 - acc: 0.8303 - val_loss: 0.4023 - val_acc: 0.8662\n",
            "Epoch 9/50\n",
            "112800/112800 [==============================] - 34s 306us/step - loss: 0.5072 - acc: 0.8309 - val_loss: 0.4064 - val_acc: 0.8621\n",
            "Epoch 10/50\n",
            "112800/112800 [==============================] - 34s 302us/step - loss: 0.5021 - acc: 0.8315 - val_loss: 0.4005 - val_acc: 0.8635\n",
            "Epoch 11/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.4992 - acc: 0.8323 - val_loss: 0.3971 - val_acc: 0.8650\n",
            "Epoch 12/50\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.4970 - acc: 0.8324 - val_loss: 0.3938 - val_acc: 0.8657\n",
            "Epoch 13/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.4909 - acc: 0.8356 - val_loss: 0.3934 - val_acc: 0.8660\n",
            "Epoch 14/50\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.4885 - acc: 0.8358 - val_loss: 0.3930 - val_acc: 0.8665\n",
            "Epoch 15/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.4844 - acc: 0.8366 - val_loss: 0.3866 - val_acc: 0.8669\n",
            "Epoch 16/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.4837 - acc: 0.8371 - val_loss: 0.3877 - val_acc: 0.8689\n",
            "Epoch 17/50\n",
            "112800/112800 [==============================] - 34s 300us/step - loss: 0.4814 - acc: 0.8380 - val_loss: 0.3837 - val_acc: 0.8695\n",
            "Epoch 18/50\n",
            "112800/112800 [==============================] - 34s 305us/step - loss: 0.4779 - acc: 0.8382 - val_loss: 0.3843 - val_acc: 0.8701\n",
            "Epoch 19/50\n",
            "112800/112800 [==============================] - 34s 299us/step - loss: 0.4745 - acc: 0.8395 - val_loss: 0.3856 - val_acc: 0.8666\n",
            "Epoch 20/50\n",
            "112800/112800 [==============================] - 34s 300us/step - loss: 0.4704 - acc: 0.8403 - val_loss: 0.3886 - val_acc: 0.8673\n",
            "Epoch 21/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.4708 - acc: 0.8408 - val_loss: 0.3797 - val_acc: 0.8708\n",
            "Epoch 22/50\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.4682 - acc: 0.8426 - val_loss: 0.3832 - val_acc: 0.8681\n",
            "Epoch 23/50\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.4674 - acc: 0.8418 - val_loss: 0.3786 - val_acc: 0.8703\n",
            "Epoch 24/50\n",
            "112800/112800 [==============================] - 34s 302us/step - loss: 0.4631 - acc: 0.8426 - val_loss: 0.3783 - val_acc: 0.8710\n",
            "Epoch 25/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.4608 - acc: 0.8432 - val_loss: 0.3752 - val_acc: 0.8705\n",
            "Epoch 26/50\n",
            "112800/112800 [==============================] - 34s 302us/step - loss: 0.4572 - acc: 0.8441 - val_loss: 0.3788 - val_acc: 0.8693\n",
            "Epoch 27/50\n",
            "112800/112800 [==============================] - 34s 305us/step - loss: 0.4565 - acc: 0.8444 - val_loss: 0.3735 - val_acc: 0.8709\n",
            "Epoch 28/50\n",
            "112800/112800 [==============================] - 34s 300us/step - loss: 0.4547 - acc: 0.8462 - val_loss: 0.3754 - val_acc: 0.8735\n",
            "Epoch 29/50\n",
            "112800/112800 [==============================] - 34s 300us/step - loss: 0.4548 - acc: 0.8449 - val_loss: 0.3725 - val_acc: 0.8722\n",
            "Epoch 30/50\n",
            "112800/112800 [==============================] - 34s 300us/step - loss: 0.4501 - acc: 0.8469 - val_loss: 0.3716 - val_acc: 0.8735\n",
            "Epoch 31/50\n",
            "112800/112800 [==============================] - 34s 300us/step - loss: 0.4504 - acc: 0.8471 - val_loss: 0.3774 - val_acc: 0.8723\n",
            "Epoch 32/50\n",
            "112800/112800 [==============================] - 34s 300us/step - loss: 0.4501 - acc: 0.8462 - val_loss: 0.3688 - val_acc: 0.8720\n",
            "Epoch 33/50\n",
            "112800/112800 [==============================] - 34s 300us/step - loss: 0.4465 - acc: 0.8478 - val_loss: 0.3733 - val_acc: 0.8700\n",
            "Epoch 34/50\n",
            "112800/112800 [==============================] - 34s 304us/step - loss: 0.4465 - acc: 0.8471 - val_loss: 0.3658 - val_acc: 0.8727\n",
            "Epoch 35/50\n",
            "112800/112800 [==============================] - 34s 301us/step - loss: 0.4433 - acc: 0.8487 - val_loss: 0.3697 - val_acc: 0.8730\n",
            "Epoch 36/50\n",
            "112800/112800 [==============================] - 34s 305us/step - loss: 0.4402 - acc: 0.8505 - val_loss: 0.3655 - val_acc: 0.8753\n",
            "Epoch 37/50\n",
            "112800/112800 [==============================] - 34s 301us/step - loss: 0.4396 - acc: 0.8496 - val_loss: 0.3693 - val_acc: 0.8720\n",
            "Epoch 38/50\n",
            "112800/112800 [==============================] - 34s 302us/step - loss: 0.4376 - acc: 0.8490 - val_loss: 0.3650 - val_acc: 0.8744\n",
            "Epoch 39/50\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.4356 - acc: 0.8505 - val_loss: 0.3679 - val_acc: 0.8726\n",
            "Epoch 40/50\n",
            "112800/112800 [==============================] - 34s 302us/step - loss: 0.4371 - acc: 0.8503 - val_loss: 0.3629 - val_acc: 0.8752\n",
            "Epoch 41/50\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.4335 - acc: 0.8512 - val_loss: 0.3666 - val_acc: 0.8742\n",
            "Epoch 42/50\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.4321 - acc: 0.8512 - val_loss: 0.3608 - val_acc: 0.8757\n",
            "Epoch 43/50\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.4295 - acc: 0.8512 - val_loss: 0.3654 - val_acc: 0.8745\n",
            "Epoch 44/50\n",
            "112800/112800 [==============================] - 34s 301us/step - loss: 0.4282 - acc: 0.8538 - val_loss: 0.3591 - val_acc: 0.8762\n",
            "Epoch 45/50\n",
            "112800/112800 [==============================] - 34s 306us/step - loss: 0.4309 - acc: 0.8523 - val_loss: 0.3603 - val_acc: 0.8756\n",
            "Epoch 46/50\n",
            "112800/112800 [==============================] - 34s 301us/step - loss: 0.4263 - acc: 0.8536 - val_loss: 0.3663 - val_acc: 0.8724\n",
            "Epoch 47/50\n",
            "112800/112800 [==============================] - 34s 302us/step - loss: 0.4278 - acc: 0.8530 - val_loss: 0.3568 - val_acc: 0.8781\n",
            "Epoch 48/50\n",
            "112800/112800 [==============================] - 34s 303us/step - loss: 0.4254 - acc: 0.8534 - val_loss: 0.3614 - val_acc: 0.8766\n",
            "Epoch 49/50\n",
            "112800/112800 [==============================] - 41s 363us/step - loss: 0.4232 - acc: 0.8534 - val_loss: 0.3594 - val_acc: 0.8781\n",
            "Epoch 50/50\n",
            "112800/112800 [==============================] - 35s 314us/step - loss: 0.4238 - acc: 0.8538 - val_loss: 0.3560 - val_acc: 0.8756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff92ac23e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "57bL37D1-LL0",
        "colab_type": "code",
        "outputId": "aa121334-8b67-468f-e461-462a2fae2a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test[50:100], Y_test[50:100], verbose=0)\n",
        "print(score)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20936107516288757, 0.9399999904632569]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "feuUrYs7KLyl",
        "colab_type": "code",
        "outputId": "c4cbac34-fdd6-40e4-fd26-1424a25521ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.6/dist-packages (0.6.7)\n",
            "Requirement already satisfied: tensorflow==1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: numpy==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.1)\n",
            "Requirement already satisfied: tensorflow-hub==0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.1.1)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: keras==2.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.2)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.32.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.1.0)\n",
            "Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.12.0->tensorflowjs)\n",
            "  Using cached https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (3.6.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.6.1)\n",
            "Collecting keras-applications>=1.0.6 (from tensorflow==1.12.0->tensorflowjs)\n",
            "  Using cached https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (3.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0->tensorflowjs) (40.6.2)\n",
            "\u001b[31mkeras 2.2.2 has requirement keras-applications==1.0.4, but you'll have keras-applications 1.0.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mkeras 2.2.2 has requirement keras-preprocessing==1.0.2, but you'll have keras-preprocessing 1.0.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-preprocessing, keras-applications\n",
            "  Found existing installation: Keras-Preprocessing 1.0.2\n",
            "    Uninstalling Keras-Preprocessing-1.0.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.2\n",
            "  Found existing installation: Keras-Applications 1.0.4\n",
            "    Uninstalling Keras-Applications-1.0.4:\n",
            "      Successfully uninstalled Keras-Applications-1.0.4\n",
            "Successfully installed keras-applications-1.0.6 keras-preprocessing-1.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WuwzZFKxKLsl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflowjs as tfjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wo3ujv9dKLpl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfjs.converters.save_keras_model(model, '/content/drive/My Drive/Datasets/')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}